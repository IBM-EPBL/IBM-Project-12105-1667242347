{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xf-nN1O5vd7U"
      },
      "source": [
        "# **IMAGE PREPROCESSING**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cOHJm9bvYJF"
      },
      "source": [
        "\n",
        "**MOUNTING THE DRIVE**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "HmKHFBqpRZ2G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7df21e1e-9824-4da7-d8bb-9a5bd8866790"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b00FC9qrkdfm"
      },
      "source": [
        "**IMPORT THE IMAGEDATAGENERATOR LIBRARY**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "F87zOCPkdi5F"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w0utuifckmxu"
      },
      "source": [
        "**CONFIGURE IMAGEDATAGENERATOR CLASS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "JH6p_ts2dfug"
      },
      "outputs": [],
      "source": [
        "train_datagen=ImageDataGenerator(rescale=1./255,shear_range=0.2,zoom_range=0.2,horizontal_flip=True)\n",
        "\n",
        "\n",
        "test_datagen=ImageDataGenerator(rescale=1./255)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zgz-1bvevrlR"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "**APPLY IMAGE DATAGENERATOR FUNCTIONALITY TO TRAINSET AND TESTSET**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "2aoOYTVwKs8N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24fabe69-be6b-4edb-d9e6-6cfecca8893d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2626 images belonging to 5 classes.\n",
            "Found 1055 images belonging to 5 classes.\n"
          ]
        }
      ],
      "source": [
        "x_train=train_datagen.flow_from_directory('/content/drive/MyDrive/Dataset/TRAIN_SET',(64,64),batch_size=5,color_mode='rgb',class_mode='sparse')\n",
        "x_test=test_datagen.flow_from_directory('/content/drive/MyDrive/Dataset/TEST_SET',(64,64),batch_size=5,color_mode='rgb',class_mode='sparse')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "kjfrUQxbRzd2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "839282e7-0785-4946-ed15-9eb07a0c278d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'APPLES': 0, 'BANANA': 1, 'ORANGE': 2, 'PINEAPPLE': 3, 'WATERMELON': 4}\n",
            "{'APPLES': 0, 'BANANA': 1, 'ORANGE': 2, 'PINEAPPLE': 3, 'WATERMELON': 4}\n"
          ]
        }
      ],
      "source": [
        "print(x_train.class_indices)\n",
        "\n",
        "print(x_test.class_indices)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "NWUM6OZtU_vv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "506f73c1-2b0e-4db6-c965-0fbf6e5e0131"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({0: 606, 1: 445, 2: 479, 3: 621, 4: 475})"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "from collections import Counter as c\n",
        "c(x_train.labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PmByLNr9v6r3"
      },
      "source": [
        "# **MODEL BUILDING**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfeEOAxKwAdK"
      },
      "source": [
        "**IMPORTING THE MODEL BUILDING LIBRARIES**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "yfg3VplJVB1h"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "from tensorflow.keras.layers import Dense,Flatten\n",
        "from tensorflow.keras.layers import Conv2D,MaxPooling2D,Dropout\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YqkEmfqjwFuD"
      },
      "source": [
        "**INITIALIZING THE MODEL**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "SHtxxZBqVGmp"
      },
      "outputs": [],
      "source": [
        "model=Sequential()\n",
        "classifier=Sequential()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rEdTioWXwKUj"
      },
      "source": [
        "**ADDING CNN LAYERS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "3ZNheNLzVfL_"
      },
      "outputs": [],
      "source": [
        "classifer=Sequential()\n",
        "classifier.add(Conv2D(32,(3,3),input_shape=(64,64,3),activation='relu'))\n",
        "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
        "classifier.add(Conv2D(32,(3,3),activation='relu'))\n",
        "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
        "classifier.add(Flatten())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rcCJpt3iwOQq"
      },
      "source": [
        "**ADDING DENSE LAYERS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "IACMj4f0XelI"
      },
      "outputs": [],
      "source": [
        "classifier.add(Dense(units=128,activation='relu'))\n",
        "classifer.add(Dense(units=5,activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "7eS1ASwRXsk9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "994deff5-c692-490e-8806-6a952abe823a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 62, 62, 32)        896       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 31, 31, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 29, 29, 32)        9248      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 14, 14, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 6272)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               802944    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 813,088\n",
            "Trainable params: 813,088\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "classifier.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ySZ5_-fwoj7"
      },
      "source": [
        "**CONFIGURE THE LEARNING PROCESS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "XsWhBcwOYPwF"
      },
      "outputs": [],
      "source": [
        "classifier.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uKyjtKE3w0E7"
      },
      "source": [
        "**TRAIN THE MODEL**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tFAde9QkWjsD",
        "outputId": "802a5b52-2bd4-44fa-90df-ab835c51c308"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "526/526 [==============================] - ETA: 0s - loss: 4.8565 - accuracy: 0.2300"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 526 batches). You may need to use the repeat() function when building your dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r526/526 [==============================] - 1304s 2s/step - loss: 4.8565 - accuracy: 0.2300 - val_loss: 4.8520 - val_accuracy: 0.1488\n",
            "Epoch 2/10\n",
            "526/526 [==============================] - 27s 50ms/step - loss: 4.8520 - accuracy: 0.2308\n",
            "Epoch 3/10\n",
            "526/526 [==============================] - 27s 51ms/step - loss: 4.8520 - accuracy: 0.2308\n",
            "Epoch 4/10\n",
            "526/526 [==============================] - 29s 54ms/step - loss: 4.8777 - accuracy: 0.2304\n",
            "Epoch 5/10\n",
            "526/526 [==============================] - 26s 49ms/step - loss: 4.8556 - accuracy: 0.2304\n",
            "Epoch 6/10\n",
            "526/526 [==============================] - 28s 54ms/step - loss: 4.8520 - accuracy: 0.2308\n",
            "Epoch 7/10\n",
            "526/526 [==============================] - 26s 50ms/step - loss: 4.8520 - accuracy: 0.2308\n",
            "Epoch 8/10\n",
            "526/526 [==============================] - 26s 49ms/step - loss: 4.8520 - accuracy: 0.2308\n",
            "Epoch 9/10\n",
            "526/526 [==============================] - 26s 49ms/step - loss: 4.8548 - accuracy: 0.2304\n",
            "Epoch 10/10\n",
            "526/526 [==============================] - 28s 53ms/step - loss: 4.8520 - accuracy: 0.2308\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa12d2860d0>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "classifier.fit_generator(generator=x_train,steps_per_epoch=len(x_train),epochs=10,validation_data=x_test,validation_steps=len(x_train))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5jZkE6AGw-HZ"
      },
      "source": [
        "**SAVE THE MODEL**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "M8QZeZt6ZHpM"
      },
      "outputs": [],
      "source": [
        "classifier.save('nutrition_analyzer.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6B1Cl3LDxAPv"
      },
      "source": [
        "**TEST THE MODEL**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "H_SFWvbTZNfE"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "from tensorflow.keras.utils import load_img, img_to_array \n",
        "from keras.preprocessing import image\n",
        "model=load_model(\"nutrition_analyzer.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img=tensorflow.keras.utils.load_img(\"/content/drive/MyDrive/Dataset/tests/app_test2.jfif\",target_size=(64,64))\n",
        "img"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "kGOwTsf3gFcM",
        "outputId": "998b18e9-4519-4f28-9e78-eef8684694ac"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=64x64 at 0x7FA1278DF210>"
            ],
            "image/png": "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\n"
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "Xs5__ngxahBA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50431811-84e1-49ad-9736-b202419bf619"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 25ms/step\n",
            "APPLES\n"
          ]
        }
      ],
      "source": [
        "img=tensorflow.keras.utils.load_img(r\"/content/drive/MyDrive/Dataset/tests/ora_test1.jfif\",grayscale=False,target_size=(64,64))\n",
        "from tensorflow.keras.utils import load_img, img_to_array \n",
        "x=img_to_array(img)\n",
        "x=np.expand_dims(x,axis=0)\n",
        "#pred=model.predict_classes(x)\n",
        "#pred = model.predict(x) \n",
        "#pred\n",
        "\n",
        "preds=model.predict(x) \n",
        "val=np.argmax(preds)\n",
        "index=['APPLES','BANANA','ORANGE','PINEAPPLE','WATERMELON']\n",
        "val\n",
        "print(str(index[val]))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}